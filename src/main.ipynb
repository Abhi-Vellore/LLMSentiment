{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhivellore/LLMSentiment/saenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pre_process import AmazonDatasetPreprocessor, KaggleDatasetPreprocessor, SentenceDatasetPreprocessor\n",
    "from config import PROCESSED_DATA_PATH\n",
    "import os\n",
    "import pandas as pd\n",
    "from gpt import ChatGPTSession\n",
    "import glob\n",
    "from llama import LLaMaSession\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from credentials import openai_api_key, llama_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ../data/processed/processed_amazon_data.csv\n",
      "Processed data saved to ../data/processed/processed_sentence_data.csv\n",
      "Processed combined Kaggle data saved to ../data/processed/processed_kaggle_combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "amazon_processor = AmazonDatasetPreprocessor('Amazon_Fashion_Review_Data.json')\n",
    "amazon_processor.preprocess()\n",
    "amazon_processor.to_csv('processed_amazon_data.csv')\n",
    "\n",
    "# Initialize and process the Sentence data\n",
    "sentence_processor = SentenceDatasetPreprocessor('Sentences_75Agree.txt')\n",
    "sentence_processor.preprocess()\n",
    "sentence_processor.to_csv('processed_sentence_data.csv')\n",
    "\n",
    "# Initialize and process the first Kaggle dataset\n",
    "kaggle1_processor = KaggleDatasetPreprocessor('kaggle_train.csv')\n",
    "kaggle1_processor.preprocess()\n",
    "\n",
    "# Initialize and process the second Kaggle dataset\n",
    "kaggle2_processor = KaggleDatasetPreprocessor('kaggle_test.csv')\n",
    "kaggle2_processor.preprocess()\n",
    "\n",
    "# Concatenate the preprocessed DataFrames\n",
    "processed_kaggle1_df = kaggle1_processor.df\n",
    "processed_kaggle2_df = kaggle2_processor.df\n",
    "combined_df = pd.concat([processed_kaggle1_df, processed_kaggle2_df], ignore_index=True)\n",
    "\n",
    "# Sample approximately 3000 rows from the combined DataFrame\n",
    "sampled_df = combined_df.sample(n=3000, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file in the processed directory\n",
    "combined_csv_path = os.path.join(PROCESSED_DATA_PATH, 'processed_kaggle_combined_data.csv')\n",
    "sampled_df.to_csv(combined_csv_path, index=False)\n",
    "print(f\"Processed combined Kaggle data saved to {combined_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Define state-saving functions\n",
    "def save_state(state_file, last_processed_index):\n",
    "    with open(state_file, 'w') as file:\n",
    "        file.write(str(last_processed_index))\n",
    "\n",
    "def load_state(state_file):\n",
    "    try:\n",
    "        with open(state_file, 'r') as file:\n",
    "            return int(file.read().strip())\n",
    "    except FileNotFoundError:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_limit = 10000\n",
    "rate_limit_per_minute = 500\n",
    "state_file_path = 'last_processed_line.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_with_GPTModel(input_csv_path, output_csv_path, chat_session, column_name, state_file):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    start_index = load_state(state_file)  # Load the last processed index\n",
    "    processed_count = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index < start_index:\n",
    "            continue  # Skip already processed rows\n",
    "\n",
    "        # Check if we've reached the daily limit before processing the next row\n",
    "        if processed_count >= daily_limit:\n",
    "            print(\"Reached the daily limit, stopping...\")\n",
    "            break\n",
    "\n",
    "        # Insert your API call here and store the response\n",
    "        response = chat_session.send_prompt(row['text'])\n",
    "        df.at[index, column_name] = response\n",
    "\n",
    "        # Save the state after each line is processed\n",
    "        save_state(state_file, index)\n",
    "        processed_count += 1\n",
    "\n",
    "        # Handle rate limiting\n",
    "        if processed_count % rate_limit_per_minute == 0 and processed_count != 0:\n",
    "            print(\"Rate limit reached, sleeping for 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    # Save the modified DataFrame\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Processing completed. Data saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_context = \"As a sentiment analysis model, rate the sentiment of the following text from 1 to 5, where 1 is very negative and 5 is very positive. Provide only the number as a response.\"\n",
    "\n",
    "# Initialize sessions for GPT-3.5-Turbo and GPT-4.0\n",
    "session_gpt_3_5 = ChatGPTSession(api_key=openai_api_key, model='gpt-3.5-turbo', rate_limit_per_minute=1000)\n",
    "session_gpt_4 = ChatGPTSession(api_key=openai_api_key, model='gpt-4.0', rate_limit_per_minute=300)\n",
    "\n",
    "session_gpt_3_5.set_context(sentiment_context)\n",
    "session_gpt_4.set_context(sentiment_context)\n",
    "\n",
    "# Process each dataset\n",
    "datasets_path = '../data/processed/*.csv'\n",
    "datasets = glob.glob(datasets_path)\n",
    "\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    output_path_3_5 = dataset.replace('.csv', '_with_gpt_3_5.csv')\n",
    "    process_dataset_with_GPTModel(dataset, output_path_3_5, session_gpt_3_5, \"GPT 3.5 Score\", state_file=state_file_path)\n",
    "    \n",
    "    # If the script has hit the daily limit, it will stop and needs to be run again the next day.\n",
    "\n",
    "    current_index = load_state(state_file_path)\n",
    "    if current_index + 1 >= daily_limit:\n",
    "        print(\"Daily limit reached, please run again tomorrow.\")\n",
    "        break  # Stop processing files if the daily limit has been reached\n",
    "\n",
    "    output_path_4 = dataset.replace('.csv', '_with_gpt_4.csv')\n",
    "    process_dataset_with_GPTModel(dataset, output_path_4, session_gpt_4, \"GPT 4.0 Score\", state_file=state_file_path)\n",
    "\n",
    "    current_index = load_state(state_file_path)\n",
    "    if current_index + 1 >= daily_limit:\n",
    "        print(\"Daily limit reached, please run again tomorrow.\")\n",
    "        break  # Stop processing files if the daily limit has been reached\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLama Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_with_llama_model(input_csv_path, output_csv_path, llama_session, column_name, state_file):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    start_index = load_state(state_file)  # Load the last processed index\n",
    "    processed_count = 0\n",
    "\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index < start_index:\n",
    "            continue  # Skip already processed rows\n",
    "\n",
    "        # Check if we've reached the daily limit before processing the next row\n",
    "        if processed_count >= daily_limit:\n",
    "            print(\"Reached the daily limit, stopping...\")\n",
    "            break\n",
    "\n",
    "        # Insert your API call here and store the response\n",
    "        response = llama_session.send_prompt(row['text'])\n",
    "        df.at[index, column_name] = response\n",
    "\n",
    "        # Save the state after each line is processed\n",
    "        save_state(state_file, index)\n",
    "        processed_count += 1\n",
    "\n",
    "        # Handle rate limiting\n",
    "        if processed_count % rate_limit_per_minute == 0 and processed_count != 0:\n",
    "            print(\"Rate limit reached, sleeping for 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    # Save the modified DataFrame\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Processing completed. Data saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_context = \"As a sentiment analysis model, rate the sentiment of the following text from 1 to 5, where 1 is very negative and 5 is very positive. Provide only the number as a response.\"\n",
    "\n",
    "# Initialize sessions for GPT-3.5-Turbo and GPT-4.0\n",
    "session_llama_7b = LLaMaSession(api_key=llama_api_key, model='llama-7b-chat', rate_limit_per_minute=1000)\n",
    "session_llama_13b = LLaMaSession(api_key=llama_api_key, model='llama-13b-chat', rate_limit_per_minute=300)\n",
    "\n",
    "datasets_path = '../data/processed/*.csv'\n",
    "datasets = glob.glob(datasets_path)\n",
    "\n",
    "# Process each dataset with both models\n",
    "for dataset in datasets:\n",
    "    output_path_7b = dataset.replace('.csv', '_with_7b.csv')\n",
    "    process_dataset_with_llama_model(dataset, output_path_7b, session_llama_7b, \"Llama 7B Score\", state_file=state_file_path)\n",
    "    \n",
    "    output_path_all = dataset.replace('.csv', '_with_all.csv')\n",
    "    process_dataset_with_llama_model(dataset, output_path_all, session_llama_13b, \"Llama 13B Score\", state_file=state_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "api_key = llama_api_key \n",
    "model = \"llama-7b-chat\"  \n",
    "rate_limit_per_minute = 120 \n",
    "\n",
    "# Initialize the LLaMa API session\n",
    "llama_session = LLaMaSession(api_key, model, rate_limit_per_minute)\n",
    "\n",
    "df = pd.read_csv('test_experiment.csv')\n",
    "\n",
    "# Define a function that will apply sentiment analysis to a text\n",
    "def apply_sentiment_analysis(text):\n",
    "    try:\n",
    "        return llama_session.analyze_sentiment(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing text '{text}': {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply sentiment analysis to each row of the DataFrame\n",
    "df['llama score'] = df['Text'].apply(apply_sentiment_analysis)\n",
    "\n",
    "# Save the DataFrame with the new \"llama score\" column to a new CSV file\n",
    "df.to_csv('test_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Method to process all GPT\n",
    "def process_dataset_with_GPTmodel(input_csv_path, output_csv_path, chat_session, column_name):\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    if \"text\" not in df.columns:\n",
    "        raise ValueError(\"The dataset must have a 'text' column.\")\n",
    "    \n",
    "    # Apply the model to the \"text\" column and save the results in a new column\n",
    "    df[column_name] = df['text'].apply(lambda x: chat_session.send_prompt(x))\n",
    "    \n",
    "    # Save the modified DataFrame\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
